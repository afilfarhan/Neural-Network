{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SCRIPT_DIR = Path.cwd()\n",
    "sys.path.append(str(SCRIPT_DIR.parent))\n",
    "\n",
    "from util_data.dataIterator import DataIterator\n",
    "tf.compat.v1.disable_eager_execution() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(open(\"training_data/mushrooms_training_data.npy\", 'rb'))\n",
    "training_labels = np.load(open(\"training_data/mushrooms_training_labels.npy\", 'rb'))\n",
    "validation_data = np.load(open(\"training_data/mushrooms_validation_data.npy\", 'rb'))\n",
    "validation_labels = np.load(open(\"training_data/mushrooms_validation_labels.npy\", 'rb'))\n",
    "test_data = np.load(open(\"training_data/mushrooms_test_data.npy\", 'rb'))\n",
    "test_labels = np.load(open(\"training_data/mushrooms_test_labels.npy\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print data types and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data type = <class 'numpy.ndarray'>\n",
      "Training data shape = (6500, 117)\n",
      "Training labels shape = (6500, 1)\n",
      "Validation data shape = (812, 117)\n",
      "Validation labels shape = (812, 1)\n",
      "Test data shape = (812, 117)\n",
      "Test labels shape = (812, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded data type = {}\".format(type(training_data)))\n",
    "print(\"Training data shape = {}\".format(training_data.shape))\n",
    "print(\"Training labels shape = {}\".format(training_labels.shape))\n",
    "print(\"Validation data shape = {}\".format(validation_data.shape))\n",
    "print(\"Validation labels shape = {}\".format(validation_labels.shape))\n",
    "print(\"Test data shape = {}\".format(test_data.shape))\n",
    "print(\"Test labels shape = {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "fully_connected_layers=3\n",
    "fully_connected_size=50\n",
    "fully_connected_activationfunction=tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'inputs_41:0' shape=(0,) dtype=float32>\n",
      "<tf.Variable 'labels_39:0' shape=(0,) dtype=float32>\n",
      "<tf.Variable 'learning_rate_39:0' shape=() dtype=float32>\n",
      "<tf.Variable 'global_step_1:0' shape=() dtype=int32>\n"
     ]
    }
   ],
   "source": [
    "#placeholders data input\n",
    "\n",
    "# Data inputs\n",
    "x = tf.Variable(initial_value=tf.constant([], dtype=tf.float32), trainable=False, name=\"inputs\")\n",
    "print(x)\n",
    "\n",
    "# Labels inputs\n",
    "y = tf.Variable(initial_value=tf.constant([], dtype=tf.float32), trainable=False, name=\"labels\")\n",
    "print(y)\n",
    "\n",
    "# Learning rate input\n",
    "learning_rate_input = tf.Variable(initial_value=tf.constant(0.0, dtype=tf.float32), trainable=False, name=\"learning_rate\")\n",
    "print(learning_rate_input)\n",
    "\n",
    "# Used in training to keep track of variables updates\n",
    "global_step = tf.Variable(initial_value=0, trainable=False, dtype=tf.int32, name=\"global_step\")\n",
    "print(global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'hj:0' shape=() dtype=int32>\n"
     ]
    }
   ],
   "source": [
    "print(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1_5/Relu:0\", shape=(None, 50), dtype=float32)\n",
      "Tensor(\"dense_2_2/Relu:0\", shape=(None, 50), dtype=float32)\n",
      "Tensor(\"dense_3_2/Relu:0\", shape=(None, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#creating hidden layers for the model\n",
    "\n",
    "dense_layers=fully_connected_layers\n",
    "\n",
    "dense = tf.keras.layers.Dense(units=fully_connected_size,\n",
    "                              activation=fully_connected_activationfunction,\n",
    "                              name=\"dense_1\")(x)\n",
    "print(dense)\n",
    "\n",
    "dense_layers -=1\n",
    "dense_layer_count= 2\n",
    "\n",
    "for i in range(dense_layers):\n",
    "    # Shape: (batch_size, fully_connected_size)\n",
    "    dense = tf.keras.layers.Dense(units=fully_connected_size,\n",
    "                                  activation=fully_connected_activationfunction,\n",
    "                                  name=\"dense_{}\".format(dense_layer_count))(dense)\n",
    "\n",
    "    print(dense)\n",
    "\n",
    "    dense_layer_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output/Sigmoid:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Shape: (batch_size, 1)\n",
    "output_layer = tf.keras.layers.Dense( \n",
    "                               units=1, \n",
    "                               activation=tf.nn.sigmoid,\n",
    "                               name=\"output\")(dense)\n",
    "\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cost_and_optimizer_7/loss_op:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"cost_and_optimizer_7/cost:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "minimize() got an unexpected keyword argument 'global_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40324\\349580110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Trining operation. Perform one parameters update. Increment global_step by 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtraining_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: minimize() got an unexpected keyword argument 'global_step'"
     ]
    }
   ],
   "source": [
    "#cost optimzer\n",
    "\n",
    "with tf.name_scope(\"cost_and_optimizer\"):\n",
    "    \n",
    "    # Loss value for the model output of each data point fed to the graph\n",
    "    # Shape: (batch_size, 1)\n",
    "    loss_op = tf.nn.sigmoid_cross_entropy_with_logits(labels=y,\n",
    "                                                      logits=output_layer,\n",
    "                                                      name=\"loss_op\")\n",
    "    print(loss_op)\n",
    "    \n",
    "    # Cost value for all the data points fed to the model\n",
    "    # Shape: ()\n",
    "    cost = tf.reduce_sum(loss_op, name=\"cost\")\n",
    "    print(cost)\n",
    "    \n",
    "    # Model optimizer\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                                 name=\"gradient_descent_optimizer\")\n",
    "    \n",
    "    # Trining operation. Perform one parameters update. Increment global_step by 1.\n",
    "    training_op = optimizer.minimize(cost, global_step=global_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
